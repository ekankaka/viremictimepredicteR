library(tidyverse)
library(beeswarm)
library(readxl)
library(writexl)
library(loo)  # For WAIC and LOOIC computation
library(ggbeeswarm)
library(ggpubr) # For ggarrange
# data
df = read.csv("distances_and_tsi.csv")
df1 = read.csv("distances_and_tsi_with_gp41_and_RT_Mean.csv")
# training dataset: filter for regions with at least min_sequences
df2 <- df1 %>%
mutate(cohort = str_extract(str_extract(file,"[^/]*"),"[^_]*$")) %>%
filter(!is.na(TSI) & !is.na(rawMPD)) %>%
filter(!(id %in% c("214", "217"))) %>% # Participant 214 seems to have an an outlier distance value
group_by(sequence_type,region) %>%
mutate(group_count = n())
# model string
mod_string= "model {
for (i in 1:length(y)) {
y[i] ~ dnorm(mu[i], prec_y[i])
mu[i] = a + b * x[i]
yhat[i] = mu[i]
prec_y[i] = w[i] * prec_sig # apply weights
}
a ~ ddexp(0, 1)
b ~ dnorm(0, 1/1e6)
prec_sig ~ dgamma(0.5, 0.5) # Jeffrey's prior for normal distribution's precision
sig2 = 1.0 / prec_sig
sig = sqrt(sig2)
}"
mod2_string = "
model {
for (i in 1:length(y)) {
delta[i] <- max(0, x[i] - knot)
mu[i] <- a + b1 * x[i] + b2 * delta[i]
y[i] ~ dnorm(mu[i], prec_y[i])
yhat[i] <- mu[i]
prec_y[i] <- w[i] * prec_sig
}
a ~ ddexp(0, 1)
b1 ~ dnorm(0, 1/1e6)
b2 ~ dnorm(0, 1/1e6)
knot ~ dnorm(0.015, pow(0.01, -2))
prec_sig ~ dgamma(0.5, 0.5)
sig2 <- 1.0 / prec_sig
sig <- sqrt(sig2)
}
"
out = data.frame(sequence_type = NA,
region = NA,
weights_wethod = NA,
distance_metric = NA,
post_predictive_sd = NA,
post_predictive_interval = NA,
DIC = NA,
MAE = NA,
#WAIC = NA,
LOOIC=NA,
influential_points = NA,
model = NA)
samples = list()
yhat = list()
residuals = list()
y_values = list()
out2 = data.frame(sequence_type = NA,
region = NA,
weights_wethod = NA,
distance_metric = NA,
post_predictive_sd = NA,
post_predictive_interval = NA,
DIC = NA,
MAE = NA,
#WAIC = NA,
LOOIC=NA,
influential_points = NA,
model = NA)
samples2 = list()
yhat2 = list()
residuals2 = list()
y_values2 = list()
count=1
sequence_types = sort(unique(df2$sequence_type))
for (i in 1:length(sequence_types)){
sequence_type = sequence_types[i]
# regions
regions = sort(unique(df2$region))
for (j in 1:length(regions)){
region = regions[j]
# distance metrics
distance_metrics = c("rawMPD", "tn93MPD", "rawPI", "tn93PI", "WFPS", "WFPScodons")
for (k in 1:length(distance_metrics)){
distance_metric = distance_metrics[k]
dat = df2[df2$sequence_type == sequence_type & df2$region == region,]
if (nrow(dat) > 0){
# filtered dataset
distance_metric_idx = match(distance_metric, names(dat))
x = dat[, distance_metric_idx][[1]]
y = dat$TSI
# apply weights using any of four methods:
## None, uniqueseqs as-is, normalized, log-transformed
for (m in 1:3){
print("###########################################")
# weights
weights <- case_when(
m == 1 ~  rep(1, length(dat$uniqueseqs)),
m == 2 ~ dat$uniqueseqs,
m == 3 ~ log(dat$uniqueseqs),
TRUE ~ NA)
weights_method <- case_when(
m == 1 ~ "None",
m == 2 ~ "UniqueseqsAsis",
m == 3 ~ "UniqueseqsLogTransformed",
TRUE ~ NA)
print(paste(sequence_type, region, distance_metric,"weights=",
weights_method, sep = " "))
data_jags = list(x=x, y=y, w = weights)
#########################
# model 1
#########################
params = c("a", "b", "sig", "yhat")
mod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod, 1e3)
mod_sim = coda.samples(model=mod, variable.names=params, n.iter=1e5, thin = 100)
mod_csim = as.mcmc(do.call(rbind, mod_sim))
# model diagnostics: WAIC and MAE
## DIC
dic = dic.samples(mod, n.iter = 1e3)
dic_value = sum(mean(as.vector(dic$deviance)) + as.numeric(dic$penalty))
## convert samples to matrix
samples_matrix <- as.matrix(mod_sim)
## posterior predictive means
posterior_a <- samples_matrix[, "a"]
posterior_b <- samples_matrix[, "b"]
## predicted values for each posterior sample
n <- nrow(dat)
x=dat$tn93PI
y_pred_matrix <- outer(posterior_a, rep(1,n)) + outer(posterior_b, x)
# posterior predictive standard deviation
post_predictive_sd = mean(apply(y_pred_matrix, 2, sd))
# posterior predictive interval
interval_width <- apply(y_pred_matrix, 2, function(p) quantile(p, 0.975) - quantile(p, 0.025))
post_predictive_interval <- mean(interval_width)
## posterior predictive mean (point estimate for each y)
y_pred_mean <- colMeans(y_pred_matrix)
## mean absolute error
y=dat$TSI
MAE <- mean(abs(y - y_pred_mean))
## WAIC and LOO-CV
log_lik_matrix <- matrix(NA, nrow = nrow(samples_matrix), ncol = n)
for (i in 1:nrow(samples_matrix)) {
log_lik_matrix[i, ] <- dnorm(y, mean = samples_matrix[i, "a"] + samples_matrix[i, "b"] * x, sd = samples_matrix[i, "sig"], log = TRUE)
}
#waic_result <- waic(log_lik_matrix)
loo_result <- loo(log_lik_matrix)
# influential points
influential_points <- which(loo_result$diagnostics$pareto_k > 0.7)
n_influential_points <- length(influential_points)
result = data.frame(sequence_type = sequence_type,
region = region,
weights_wethod = weights_method,
distance_metric = distance_metric,
post_predictive_sd = post_predictive_sd,
post_predictive_interval = post_predictive_interval,
DIC = dic_value,
MAE = MAE,
#WAIC = waic_result$estimates[3,1],
LOOIC=loo_result$estimates[3,1],
influential_points = n_influential_points,
model = "linear regression")
out = data.frame(rbind(out, result))
# label to use in stored output
label = paste(sequence_type, region, weights_method, distance_metric, sep = "_")
# add to list of mcmc output
samples[[label]] <- mod_sim
count = count + 1
# predicted and residuals
yhat_now = colMeans(as.matrix(mod_csim)[, grep("yhat", colnames(as.matrix(mod_csim)))])
resid = data_jags$y - yhat_now
yhat[[label]] <- yhat_now
residuals[[label]] <- resid
y_values[[label]] <- y
#########################
# model 2
#########################
params2 = c("a", "b1", "b2", "sig", "yhat", "knot")
mod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)
update(mod2, 1e3)
mod2_sim = coda.samples(model=mod2, variable.names=params2, n.iter=1e5, thin = 100)
mod2_csim = as.mcmc(do.call(rbind, mod2_sim))
# model diagnostics: WAIC2 and MAE2
## dic2
dic2 = dic.samples(mod2, n.iter = 1e3)
dic2_value = sum(mean(as.vector(dic2$deviance)) + as.numeric(dic2$penalty))
## convert samples to matrix
samples_matrix2 <- as.matrix(mod2_sim)
## posterior predictive means
posterior_a <- samples_matrix2[, "a"]
posterior_b1 <- samples_matrix2[, "b1"]
posterior_b2 <- samples_matrix2[, "b2"]
posterior_knot <- samples_matrix2[, "knot"]
## predicted values for each posterior sample
n <- nrow(dat)
x=dat$tn93PI
x_matrix <- matrix(rep(x, each = length(posterior_a)), nrow = length(posterior_a))
delta_matrix = pmax(0, x_matrix - posterior_knot)
y_pred_matrix2 <- posterior_a + posterior_b1 * x_matrix + posterior_b2 * delta_matrix
# posterior predictive standard deviation
post_predictive_sd2 = mean(apply(y_pred_matrix2, 2, sd))
# posterior predictive interval width
interval_width2 <- apply(y_pred_matrix2, 2, function(p) quantile(p, 0.975) - quantile(p, 0.025))
post_predictive_interval2 <- mean(interval_width2)
## posterior predictive mean (point estimate for each y)
y_pred_mean2 <- colMeans(y_pred_matrix2)
## mean absolute error
y=dat$TSI
MAE2 <- mean(abs(y - y_pred_mean2))
## WAIC2 and LOO-CV
print("Now at ... Log likelihood2")
S <- nrow(samples_matrix)  # Number of posterior samples
n <- length(y)             # Number of data points
log_lik_matrix2 <- matrix(NA, nrow = S, ncol = n)
for (i in 1:S) {
a    <- samples_matrix2[i, "a"]
b1   <- samples_matrix2[i, "b1"]
b2   <- samples_matrix2[i, "b2"]
knot <- samples_matrix2[i, "knot"]
sig  <- samples_matrix2[i, "sig"]
delta <- pmax(0, x - knot)
mu    <- a + b1 * x + b2 * delta
log_lik_matrix2[i, ] <- dnorm(y, mean = mu, sd = sig, log = TRUE)
}
#WAIC2_result <- WAIC2(log_lik_matrix2)
loo_result2 <- loo(log_lik_matrix2)
# influential points
print("Now at ... influential points2")
influential_points2 <- which(loo_result2$diagnostics$pareto_k > 0.7)
n_influential_points2 <- length(influential_points2)
result2 = data.frame(sequence_type = sequence_type,
region = region,
weights_wethod = weights_method,
distance_metric = distance_metric,
post_predictive_sd = post_predictive_sd2,
post_predictive_interval = post_predictive_interval2,
DIC = dic2_value,
MAE = MAE2,
#WAIC = WAIC2_result$estimates[3,1],
LOOIC=loo_result2$estimates[3,1],
influential_points = n_influential_points2,
model = "Piecewise linear regression")
out2 = data.frame(rbind(out2, result2))
# label to use in stored output
label = paste(sequence_type, region, weights_method, distance_metric, sep = "_")
# add to list of mcmc output
samples2[[label]] <- mod2_sim
count = count + 1
# predicted and residuals
print("Now at ... residuals2")
yhat2_now = colMeans(as.matrix(mod2_csim)[, grep("yhat", colnames(as.matrix(mod2_csim)))])
resid2 = data_jags$y - yhat2_now
yhat2[[label]] <- yhat2_now
residuals2[[label]] <- resid2
y_values2[[label]] <- y
}
} else {
print(paste("No data for", sequence_type, distance_metric))
}
}
}
}
out = out %>%  arrange(sequence_type, region, weights_method, influential_points,MAE)
out2 = out2 %>%  arrange(sequence_type, region, weights_method, influential_points,MAE)
out_combined = data.frame(rbind(out,out2))
#write.csv(out_combined, "model_comparisons_linearandpiecewiselinear.csv", row.names = F)
write_xlsx(out_combined, "model_comparisons_linearandpiecewiselinear.xlsx")
write_rds(c(samples, samples2), "samples_linearandpiecewiselinear.rds", compress = "gz")
write_rds(c(yhat,yhat2), "yhat_linearandpiecewiselinear.rds", compress = "gz")
write_rds(c(residuals,residuals2), "residuals_linearandpiecewiselinear.rds", compress = "gz")
write_rds(c(y_values,y_values2), "yvalues_linearandpiecewiselinear.rds", compress = "gz")
###########################
# Load data ####
yhat_mod <- readRDS("yhat_linearandpiecewiselinear.rds")
yvalues_mod <- readRDS("yvalues_linearandpiecewiselinear.rds")
i=72
name <- names(yhat_mod)[[i]]
name
yhat_mod[[i]]
yhat = yhat_mod[[i]]
yvalues = yvalues_mod[[i]]
name <- names(yhat_mod)[[i]]
name
length(yhat_mod)/2
# yhat df
yhat_df  = data.frame(model_type = NA,
name = NA,
yhat = NA,
yvalue = NA)
###########################
# Load data ####
yhat_mod <- readRDS("yhat_linearandpiecewiselinear.rds")
yvalues_mod <- readRDS("yvalues_linearandpiecewiselinear.rds")
# yhat df
yhat_df  = data.frame(model_type = NA,
name = NA,
yhat = NA,
yvalue = NA)
for (i in 72:length(yhat_mod)){
model_type = ifelse(i < length(yhat_mod)/2, "linear regression", "piecewise linear regression")
name <- names(yhat_mod)[[i]]
yhat = yhat_mod[[i]]
yvalues = yvalues_mod[[i]]
yhat_df = data.frame(rbind(yhat_df,
c(rep(model_type,length(yhat)),
rep(name,length(yhat)),
yhat,
yvalues)))
}
# yhat df
yhat_df  = data.frame(model_type = NA,
name = NA,
yhat = NA,
yvalue = NA)
for (i in 1:length(yhat_mod)){
model_type = ifelse(i < length(yhat_mod)/2, "linear regression", "piecewise linear regression")
name <- names(yhat_mod)[[i]]
yhat = yhat_mod[[i]]
yvalues = yvalues_mod[[i]]
yhat_df = data.frame(rbind(yhat_df,
c(rep(model_type,length(yhat)),
rep(name,length(yhat)),
yhat,
yvalues)))
}
View(yhat_df)
length(yhat)
rep(model_type,length(yhat))
df = data.frame(
model_type = rep(model_type,length(yhat)),
name = rep(name,length(yhat)),
yhat = yhat,
yvalue = yvalues)
View(df)
# yhat df
yhat_df  = data.frame(model_type = NA,
name = NA,
yhat = NA,
yvalue = NA)
for (i in 1:length(yhat_mod)){
model_type = ifelse(i < length(yhat_mod)/2, "linear regression", "piecewise linear regression")
name <- names(yhat_mod)[[i]]
yhat = yhat_mod[[i]]
yvalues = yvalues_mod[[i]]
df_new = data.frame(
model_type = rep(model_type,length(yhat)),
name = rep(name,length(yhat)),
yhat = yhat,
yvalue = yvalues)
yhat_df = data.frame(rbind(yhat_df,df_new))
}
View(yhat_df)
# yhat df
yhat_df  = data.frame(model_type = NA,
name = NA,
yhat = NA,
yvalue = NA)
for (i in 1:length(yhat_mod)){
model_type = ifelse(i < length(yhat_mod)/2, "linear regression", "piecewise linear regression")
name <- names(yhat_mod)[[i]]
yhat = yhat_mod[[i]]
yvalues = yvalues_mod[[i]]
df_new = data.frame(
model_type = rep(model_type,length(yhat)),
name = rep(name,length(yhat)),
yhat = yhat,
yvalue = yvalues)
yhat_df = data.frame(rbind(yhat_df,df_new)) %>% filter(!is.na(name))
}
yhat_df.s = yhat_df %>%
filter(model_type == "linear regression" &
grepl("gp41_and_RT_Mean_None", name))
View(yhat_df.s)
yhat_df.s = yhat_df %>%
mutate(diversity_metric = str_extract(name, "[^_]*$")) %>%
filter(model_type == "linear regression" &
grepl("gp41_and_RT_Mean_None", name))
yhat_df.s = yhat_df %>%
mutate(diversity_metric = str_extract(name, "[^_]*$")) %>%
filter(model_type == "linear regression" &
grepl("gp41_and_RT_Mean_None", name))
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat, color = diversity_metric)) +
geom_point(pch = 21)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
color = diversity_metric)) +
geom_point(pch = 21) +
geom_smooth()
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
color = diversity_metric)) +
geom_point(pch = 21) +
geom_smooth(method = "gam")
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
color = diversity_metric)) +
geom_point(pch = 21) +
geom_smooth(method = "gam", se = F)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
color = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(method = "gam", se = F)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(method = "gam", se = F)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = F)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = F) +
facet_wrap(diversity_metric)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = F) +
facet_wrap(~diversity_metric)
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = F) +
facet_wrap(~diversity_metric) +
theme_bw()
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = F) +
labs(y = "Error (True value - Predicted)", x = "True Value") +
facet_wrap(~diversity_metric) +
theme_bw() +
labs()
)
(p1 <- ggplot(yhat_df.s, aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = T) +
labs(y = "Error (True value - Predicted)", x = "True Value") +
facet_wrap(~diversity_metric) +
theme_bw() +
labs()
)
(p1 <- ggplot(subset(yhat_df.s, !grepl("WFPS", name)), aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = T) +
labs(y = "Error (True value - Predicted)", x = "True Value") +
facet_wrap(~diversity_metric) +
theme_bw() +
labs()
)
png("predictionerror_vs_TSI.png", width = 10, height = 10, units = "in", res = 300)
p1
dev.off()
(p1 <- ggplot(subset(yhat_df.s, !grepl("WFPS", name)), aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = T) +
labs(y = "Error (True value - Predicted)", x = "True Value") +
facet_wrap(~diversity_metric) +
theme_bw() +
theme(axis.text = element_text(size = 16),
axis.title = element_text(size = 18))
)
png("predictionerror_vs_TSI.png", width = 10, height = 7, units = "in", res = 300)
p1
dev.off()
(p1 <- ggplot(subset(yhat_df.s, !grepl("WFPS", name)), aes(x = yvalue, y = yvalue - yhat,
fill = diversity_metric)) +
geom_point(pch = 21, size = 4) +
geom_smooth(aes(color = diversity_metric), method = "gam", se = T) +
labs(y = "Estimation error (True value - Predicted)", x = "True Value") +
facet_wrap(~diversity_metric) +
theme_bw() +
theme(axis.text = element_text(size = 16),
axis.title = element_text(size = 18))
)
png("predictionerror_vs_TSI.png", width = 10, height = 7, units = "in", res = 300)
p1
dev.off()
devtools::install_github("ekankaka/viremictimepredicteR")
install.packages("devtools")
devtools::install_github("ekankaka/viremictimepredicteR")
devtools::install_github("ekankaka/viremictimepredicteR")
devtools::install_github("ekankaka/viremictimepredicteR")
library(devtools)
devtools::install_github("ekankaka/viremictimepredicteR")
devtools::install_github("ekankaka/viremictimepredicteR")
devtools::install_github("ekankaka/viremictimepredicteR")
devtools::install_github("ekankaka/viremictimepredicteR")
getwd()
setwd("viremictimepredicteR/")
getwd()
devtools::document()
devtools::install_github("ekankaka/viremictimepredicteR")
